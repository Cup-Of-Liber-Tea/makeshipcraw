import time
import json
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

def extract_category_with_infinite_scroll(category_name, url, max_products=1000):
    """
    íŠ¹ì • ì¹´í…Œê³ ë¦¬ì—ì„œ ë¬´í•œ ìŠ¤í¬ë¡¤ì„ í†µí•´ ëª¨ë“  ìƒí’ˆì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """
    print(f"\n=== {category_name} ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì¤‘ ===")
    print(f"URL: {url}")
    
    # Chrome ì˜µì…˜ ì„¤ì •
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
    
    driver = None
    
    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        
        # ìë™í™” ê°ì§€ ë°©ì§€
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        driver.get(url)
        time.sleep(3)
        
        all_discovered_links = set()
        consecutive_no_change = 0
        max_no_change = 5
        scroll_cycle = 0
        max_cycles = 100
        
        while scroll_cycle < max_cycles and consecutive_no_change < max_no_change:
            scroll_cycle += 1
            
            # í˜„ì¬ í˜ì´ì§€ì˜ ìƒí’ˆ ë§í¬ ìˆ˜ì§‘
            current_links = get_current_product_links(driver)
            
            # ìƒˆë¡œ ë°œê²¬ëœ ë§í¬ ì¶”ê°€
            new_links = current_links - all_discovered_links
            all_discovered_links.update(current_links)
            
            print(f"  ì‚¬ì´í´ {scroll_cycle}: í˜„ì¬ {len(current_links)}ê°œ, ëˆ„ì  {len(all_discovered_links)}ê°œ, ì‹ ê·œ {len(new_links)}ê°œ")
            
            # ëª©í‘œ ìƒí’ˆ ìˆ˜ì— ë„ë‹¬í•˜ê±°ë‚˜ ìƒˆë¡œìš´ ë§í¬ê°€ ì—†ìœ¼ë©´
            if len(all_discovered_links) >= max_products:
                print(f"  â†’ ëª©í‘œ ìƒí’ˆ ìˆ˜({max_products}ê°œ)ì— ë„ë‹¬!")
                break
            
            if len(new_links) == 0:
                consecutive_no_change += 1
                print(f"  â†’ ìƒˆë¡œìš´ ìƒí’ˆ ì—†ìŒ ({consecutive_no_change}/{max_no_change})")
            else:
                consecutive_no_change = 0
            
            # í˜„ì¬ ìƒí’ˆ ìˆ˜ê°€ ê¸‰ê²©íˆ ì¤„ì–´ë“¤ë©´ (ì´ˆê¸°í™” ê°ì§€) ì¢…ë£Œ
            if len(current_links) < 20 and len(all_discovered_links) > 100:
                print(f"  â†’ í˜ì´ì§€ ì´ˆê¸°í™” ê°ì§€, ìˆ˜ì§‘ ì¢…ë£Œ")
                break
            
            # ìŠ¤í¬ë¡¤ ë™ì‘
            try:
                body = driver.find_element(By.TAG_NAME, 'body')
                
                # Homeìœ¼ë¡œ ë§¨ ìœ„ë¡œ
                body.send_keys(Keys.HOME)
                time.sleep(0.5)
                
                # ì ì§„ì  ìŠ¤í¬ë¡¤
                for i in range(3):
                    body.send_keys(Keys.PAGE_DOWN)
                    time.sleep(0.3)
                
                # Endë¡œ ë§¨ ì•„ë˜ë¡œ
                body.send_keys(Keys.END)
                time.sleep(1)
                
                # ì¶”ê°€ End í‚¤ ì…ë ¥
                for i in range(2):
                    body.send_keys(Keys.END)
                    time.sleep(0.5)
                
                time.sleep(2)  # ë¡œë”© ì‹œê°„ í™•ë³´
                
            except Exception as e:
                print(f"  â†’ ìŠ¤í¬ë¡¤ ì¤‘ ì˜¤ë¥˜: {e}")
                break
        
        print(f"  âœ… {category_name}: {len(all_discovered_links)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ")
        return sorted(list(all_discovered_links))
        
    except Exception as e:
        print(f"  âŒ {category_name} ì˜¤ë¥˜: {e}")
        return []
    finally:
        if driver:
            driver.quit()

def get_current_product_links(driver):
    """
    í˜„ì¬ í˜ì´ì§€ì—ì„œ ìƒí’ˆ ë§í¬ë“¤ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """
    try:
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')
        
        product_links = set()
        
        # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ìƒí’ˆ ë§í¬ ì°¾ê¸°
        patterns = [
            'a[href*="/products/"]',
            '.product-card a',
            '.product-item a',
            '.campaign-card a',
            '.grid-item a',
            '[data-product] a'
        ]
        
        for pattern in patterns:
            links = soup.select(pattern)
            for link in links:
                href = link.get('href')
                if href and '/products/' in href:
                    if href.startswith('/'):
                        full_url = f"https://www.makeship.com{href}"
                    elif href.startswith('http'):
                        full_url = href
                    else:
                        continue
                    
                    # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°í•˜ì—¬ ì •ë¦¬
                    clean_url = full_url.split('?')[0]
                    product_links.add(clean_url)
        
        # ë°±ì—… ë°©ë²•: ëª¨ë“  a íƒœê·¸ ê²€ì‚¬
        all_links = soup.find_all('a', href=True)
        for link in all_links:
            href = link['href']
            if '/products/' in href:
                if href.startswith('/'):
                    full_url = f"https://www.makeship.com{href}"
                elif href.startswith('http'):
                    full_url = href
                else:
                    continue
                
                clean_url = full_url.split('?')[0]
                product_links.add(clean_url)
        
        return product_links
        
    except Exception as e:
        return set()

def save_links_clean(links, filename):
    """
    ë§í¬ë§Œ ê¹”ë”í•˜ê²Œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            for link in links:
                f.write(f"{link}\n")
        print(f"  ğŸ“ {len(links)}ê°œ ë§í¬ê°€ '{filename}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"  âŒ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")

def save_category_results(all_results, timestamp):
    """
    ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ë¥¼ JSONê³¼ í…ìŠ¤íŠ¸ë¡œ ì €ì¥
    """
    # JSON í˜•íƒœë¡œ ì €ì¥
    json_filename = f"makeship_all_products_{timestamp}.json"
    try:
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ê°€ '{json_filename}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ JSON ì €ì¥ ì˜¤ë¥˜: {e}")
    
    # ëª¨ë“  ê³ ìœ  ë§í¬ ì¶”ì¶œ ë° ì €ì¥
    all_unique_links = set()
    for category_links in all_results.values():
        all_unique_links.update(category_links)
    
    unique_filename = f"makeship_unique_products_{timestamp}.txt"
    save_links_clean(sorted(list(all_unique_links)), unique_filename)
    
    return len(all_unique_links)

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ëª¨ë“  ì¹´í…Œê³ ë¦¬ì— ë¬´í•œ ìŠ¤í¬ë¡¤ ì ìš©
    """
    print("ğŸš€ Makeship ì „ì²´ ì¹´í…Œê³ ë¦¬ ë¬´í•œ ìŠ¤í¬ë¡¤ ì¶”ì¶œê¸°")
    print("ëª¨ë“  ì¹´í…Œê³ ë¦¬ì— ë¬´í•œ ìŠ¤í¬ë¡¤ì„ ì ìš©í•˜ì—¬ ìµœëŒ€í•œ ë§ì€ ìƒí’ˆì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
    print("="*70)
    
    # ì¹´í…Œê³ ë¦¬ URL ëª©ë¡ (pastëŠ” 805ê°œ í•œê³„ ì ìš©)
    category_configs = {
        "í›„ë””": {
            "url": "https://www.makeship.com/shop/hoodies", 
            "max_products": 200
        },
        "ë‹ˆíŠ¸ í¬ë£¨ë„¥": {
            "url": "https://www.makeship.com/shop/knitted-crewnecks", 
            "max_products": 100
        },
        "í‹°ì…”ì¸ ": {
            "url": "https://www.makeship.com/shop/t-shirts", 
            "max_products": 100
        },
        "ì—ë‚˜ë©œ í•€": {
            "url": "https://www.makeship.com/shop/enamel-pins", 
            "max_products": 200
        },
        "ë¹„ë‹ í”¼ê·œì–´": {
            "url": "https://www.makeship.com/shop/vinyl-figures", 
            "max_products": 200
        },
        "í”ŒëŸ¬ì‹œ": {
            "url": "https://www.makeship.com/shop/plushies", 
            "max_products": 300
        },
        "ë¡±ë³´ì´": {
            "url": "https://www.makeship.com/shop/longbois", 
            "max_products": 100
        },
        "ë„ìš°ë³´ì´": {
            "url": "https://www.makeship.com/shop/doughbois", 
            "max_products": 100
        },
        "ì ë³´ í”ŒëŸ¬ì‹œ": {
            "url": "https://www.makeship.com/shop/jumbo-plushies", 
            "max_products": 100
        },
        "í‚¤ì²´ì¸ í”ŒëŸ¬ì‹œ": {
            "url": "https://www.makeship.com/shop/keychain-plushies", 
            "max_products": 200
        },
        "ì¸ê¸° ìƒí’ˆ": {
            "url": "https://www.makeship.com/shop/top", 
            "max_products": 200
        },
        "ì‹ ìƒí’ˆ": {
            "url": "https://www.makeship.com/shop/new", 
            "max_products": 200
        },
        "ì¶œì‹œ ì˜ˆì •": {
            "url": "https://www.makeship.com/shop/comingsoon", 
            "max_products": 200
        },
        "ì§€ë‚œ ìƒí’ˆ": {
            "url": "https://www.makeship.com/shop/past", 
            "max_products": 805  # PastëŠ” 805ê°œ í•œê³„
        }
    }
    
    timestamp = time.strftime('%Y%m%d_%H%M%S')
    all_results = {}
    
    start_time = time.time()
    
    for category_name, config in category_configs.items():
        category_links = extract_category_with_infinite_scroll(
            category_name, 
            config["url"], 
            config["max_products"]
        )
        
        all_results[category_name] = category_links
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê°œë³„ íŒŒì¼ë„ ì €ì¥
        category_filename = f"makeship_{category_name.replace(' ', '_')}_{timestamp}.txt"
        save_links_clean(category_links, category_filename)
        
        # ì ì‹œ ëŒ€ê¸° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
        time.sleep(2)
    
    # ì „ì²´ ê²°ê³¼ ì €ì¥
    total_unique = save_category_results(all_results, timestamp)
    
    end_time = time.time()
    elapsed_time = int(end_time - start_time)
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*70)
    print("ğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")
    print("="*70)
    
    total_links = 0
    for category_name, links in all_results.items():
        print(f"{category_name}: {len(links)}ê°œ")
        total_links += len(links)
    
    print(f"\nğŸ“Š ì´ ìƒí’ˆ ë§í¬ ìˆ˜: {total_links}ê°œ")
    print(f"ğŸ”§ ì¤‘ë³µ ì œê±° í›„ ê³ ìœ  ìƒí’ˆ: {total_unique}ê°œ")
    print(f"â±ï¸  ì†Œìš” ì‹œê°„: {elapsed_time//60}ë¶„ {elapsed_time%60}ì´ˆ")
    
    print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
    print(f"  - makeship_all_products_{timestamp}.json (ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸)")
    print(f"  - makeship_unique_products_{timestamp}.txt (ê³ ìœ  ìƒí’ˆ ë§í¬ë§Œ)")
    print(f"  - makeship_[ì¹´í…Œê³ ë¦¬]_{timestamp}.txt (ì¹´í…Œê³ ë¦¬ë³„ ê°œë³„ íŒŒì¼)")

if __name__ == "__main__":
    main()
