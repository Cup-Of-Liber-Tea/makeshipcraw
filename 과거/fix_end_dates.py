import pandas as pd
from playwright.sync_api import sync_playwright, TimeoutError
from playwright_stealth import stealth_sync
from datetime import datetime
import time

def find_missing_end_dates(excel_file_path="ìµœì¢…í•©ë³¸_ìˆ˜ì •_20250629_223209.xlsx"):
    """
    ì¢…ë£Œì¼ì´ ëˆ„ë½ëœ í–‰ë“¤ì„ ì°¾ëŠ” í•¨ìˆ˜
    """
    try:
        df = pd.read_excel(excel_file_path)
        print(f"ì—‘ì…€ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰")
        
        # ì¢…ë£Œì¼ ì»¬ëŸ¼ ì°¾ê¸°
        end_date_col = None
        url_col = None
        
        for col in df.columns:
            if 'ì¢…ë£Œì¼' in str(col):
                end_date_col = col
            elif 'URL' in str(col):
                url_col = col
        
        if end_date_col is None or url_col is None:
            print(f"ì¢…ë£Œì¼ ì»¬ëŸ¼: {end_date_col}, URL ì»¬ëŸ¼: {url_col}")
            print("í•„ìš”í•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ì¢…ë£Œì¼ì´ ëˆ„ë½ë˜ê±°ë‚˜ ë¬¸ì œê°€ ìˆëŠ” í–‰ë“¤ ì°¾ê¸°
        missing_urls = []
        for idx, row in df.iterrows():
            end_date = str(row[end_date_col]) if pd.notna(row[end_date_col]) else ""
            url = str(row[url_col]) if pd.notna(row[url_col]) else ""
            
            # ì¢…ë£Œì¼ì´ ì—†ê±°ë‚˜ ê¸°ë³¸ê°’ì¸ ê²½ìš°
            if not end_date or end_date in ["í•´ë‹¹ ì—†ìŒ", "ì¢…ë£Œì¼ ì—†ìŒ", "nan", ""]:
                missing_urls.append((idx + 1, url))  # 1-based index
        
        print(f"ì¢…ë£Œì¼ ëˆ„ë½ëœ í–‰: {len(missing_urls)}ê°œ")
        return missing_urls
        
    except Exception as e:
        print(f"íŒŒì¼ ì½ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
        return []

def extract_end_date_only(page, url):
    """
    ì¢…ë£Œì¼ë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ - ê°œì„ ëœ ë²„ì „
    """
    try:
        page.goto(url, wait_until='load', timeout=60000)
        page.wait_for_selector('[class*="ProductDetails__ProductTitle"]', timeout=30000)
    except Exception:
        print(f"í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: {url}")
        return "í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨"

    # ì¢…ë£Œì¼ ì¶”ì¶œ - ë” í¬ê´„ì ì¸ ì ‘ê·¼
    try:
        # ë¨¼ì € í˜ì´ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ ë¶„ì„
        page_text = page.locator('body').inner_text(timeout=5000)
        
        # ë‚ ì§œ íŒ¨í„´ ì°¾ê¸° (ë‹¤ì–‘í•œ í˜•ì‹)
        import re
        
        # íŒ¨í„´ë“¤ - ë” í¬ê´„ì ìœ¼ë¡œ ê°œì„ 
        date_patterns = [
            r'Ends on\s+([A-Za-z]+\s+\d{1,2},\s+\d{4})',  # "Ends on January 15, 2025"
            r'Ended:\s+([A-Za-z]+\s+\d{1,2},\s+\d{4})',   # "Ended: January 15, 2025"
            r'Ends:\s+([A-Za-z]+\s+\d{1,2},\s+\d{4})',    # "Ends: January 15, 2025"
            r'End Date:\s+([A-Za-z]+\s+\d{1,2},\s+\d{4})', # "End Date: January 15, 2025"
            r'Campaign ends\s+([A-Za-z]+\s+\d{1,2},\s+\d{4})', # "Campaign ends January 15, 2025"
            r'Campaign ended\s+([A-Za-z]+\s+\d{1,2},\s+\d{4})', # "Campaign ended January 15, 2025"
            r'Ended on\s+([A-Za-z]+\s+\d{1,2},\s+\d{4})',  # "Ended on January 15, 2025"
            r'Completed:\s+([A-Za-z]+\s+\d{1,2},\s+\d{4})', # "Completed: January 15, 2025"
            r'Finished:\s+([A-Za-z]+\s+\d{1,2},\s+\d{4})',  # "Finished: January 15, 2025"
            r'([A-Za-z]+\s+\d{1,2},\s+\d{4})\s*[\-\â€”]\s*End', # "January 15, 2025 - End"
            r'([A-Za-z]+\s+\d{1,2},\s+\d{4})\s*[\-\â€”]\s*Ended', # "January 15, 2025 - Ended"
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, page_text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        # ìƒíƒœ í™•ì¸ - ë” ì„¸ë¶„í™”ëœ ì¢…ë£Œ ìƒíƒœ
        status_patterns = [
            (r'Campaign\s+ended\s+on\s+([A-Za-z]+\s+\d{1,2},\s+\d{4})', 1),  # ë‚ ì§œ í¬í•¨
            (r'Ended\s+on\s+([A-Za-z]+\s+\d{1,2},\s+\d{4})', 1),  # ë‚ ì§œ í¬í•¨
            (r'Campaign\s+ended', 0),  # ì¼ë°˜ ì¢…ë£Œ
            (r'This\s+campaign\s+has\s+ended', 0),
            (r'Campaign\s+complete', 0),
            (r'Sold\s+out', 0),
            (r'No\s+longer\s+available', 0),
            (r'Campaign\s+closed', 0),
        ]
        
        for pattern, has_date in status_patterns:
            match = re.search(pattern, page_text, re.IGNORECASE)
            if match:
                if has_date and len(match.groups()) > 0:
                    return match.group(1).strip()  # êµ¬ì²´ì  ë‚ ì§œ ë°˜í™˜
                else:
                    return "ìº í˜ì¸ ì¢…ë£Œë¨"
        
        # ì§„í–‰ ì¤‘ì¸ì§€ í™•ì¸
        if re.search(r'days?\s+left', page_text, re.IGNORECASE):
            return "ì§„í–‰ ì¤‘ (êµ¬ì²´ì  ì¢…ë£Œì¼ ì—†ìŒ)"
        
        # íŠ¹ì • DOM ìš”ì†Œì—ì„œ ì°¾ê¸°
        selectors_to_try = [
            '[class*="countdown"]',
            '[class*="Countdown"]', 
            '[class*="timer"]',
            '[class*="Timer"]',
            '[class*="end-date"]',
            '[class*="EndDate"]',
            '[data-testid*="countdown"]',
            '[data-testid*="end"]'
        ]
        
        for selector in selectors_to_try:
            elements = page.locator(selector)
            if elements.count() > 0:
                text = elements.first.inner_text(timeout=3000)
                date_match = re.search(r'([A-Za-z]+\s+\d{1,2},\s+\d{4})', text)
                if date_match:
                    return date_match.group(1).strip()
        
        return "ì¢…ë£Œì¼ ì •ë³´ ì—†ìŒ"
        
    except Exception as e:
        return f"ì¢…ë£Œì¼ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)[:50]}"

def fix_missing_end_dates(excel_file_path="ìµœì¢…í•©ë³¸_ìˆ˜ì •_20250629_223209.xlsx", max_urls=50):
    """
    ì¢…ë£Œì¼ì´ ëˆ„ë½ëœ URLë“¤ì„ ë‹¤ì‹œ ìŠ¤í¬ë˜í•‘í•´ì„œ ì¢…ë£Œì¼ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜
    """
    missing_urls = find_missing_end_dates(excel_file_path)
    
    if not missing_urls:
        print("ì¢…ë£Œì¼ì´ ëˆ„ë½ëœ í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ì´ {len(missing_urls)}ê°œ URL ì¤‘ ìµœëŒ€ {max_urls}ê°œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    urls_to_process = missing_urls[:max_urls]
    
    # ì—‘ì…€ íŒŒì¼ ë‹¤ì‹œ ë¡œë“œ
    df = pd.read_excel(excel_file_path)
    
    # ì¢…ë£Œì¼ ì»¬ëŸ¼ ì°¾ê¸°
    end_date_col = None
    for col in df.columns:
        if 'ì¢…ë£Œì¼' in str(col):
            end_date_col = col
            break
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context()
        stealth_sync(context)
        page = context.new_page()
        
        updated_count = 0
        
        for row_idx, url in urls_to_process:
            print(f"ì²˜ë¦¬ ì¤‘: í–‰ {row_idx} - {url[:50]}...")
            
            end_date = extract_end_date_only(page, url)
            
            if end_date and end_date not in ["ì¢…ë£Œì¼ ì°¾ì„ ìˆ˜ ì—†ìŒ", "í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨"]:
                # DataFrame ì—…ë°ì´íŠ¸ (0-based index)
                df.at[row_idx - 1, end_date_col] = end_date
                updated_count += 1
                print(f"  âœ… ì—…ë°ì´íŠ¸: {end_date}")
            else:
                print(f"  âŒ ì‹¤íŒ¨: {end_date}")
            
            # ìš”ì²­ ê°„ ë”œë ˆì´
            time.sleep(1)
        
        browser.close()
    
    if updated_count > 0:
        # ìˆ˜ì •ëœ íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        new_filename = f"ìµœì¢…í•©ë³¸_ì¢…ë£Œì¼ìˆ˜ì •_{timestamp}.xlsx"
        df.to_excel(new_filename, index=False)
        print(f"\\nì¢…ë£Œì¼ ìˆ˜ì • ì™„ë£Œ! {updated_count}ê°œ í–‰ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ì €ì¥ëœ íŒŒì¼: {new_filename}")
    else:
        print("ì—…ë°ì´íŠ¸ëœ í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")

def fix_missing_end_dates_batch(excel_file_path="ìµœì¢…í•©ë³¸_ìˆ˜ì •_20250629_223209.xlsx", batch_size=100):
    """
    ì¢…ë£Œì¼ì´ ëˆ„ë½ëœ URLë“¤ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ (ì•ˆì „í•œ ëŒ€ëŸ‰ ì²˜ë¦¬)
    """
    missing_urls = find_missing_end_dates(excel_file_path)
    
    if not missing_urls:
        print("ì¢…ë£Œì¼ì´ ëˆ„ë½ëœ í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    total_urls = len(missing_urls)
    print(f"ì´ {total_urls}ê°œ URLì„ ë°°ì¹˜ ë‹¨ìœ„({batch_size}ê°œì”©)ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    # ì—‘ì…€ íŒŒì¼ ë‹¤ì‹œ ë¡œë“œ
    df = pd.read_excel(excel_file_path)
    
    # ì¢…ë£Œì¼ ì»¬ëŸ¼ ì°¾ê¸°
    end_date_col = None
    for col in df.columns:
        if 'ì¢…ë£Œì¼' in str(col):
            end_date_col = col
            break
    
    total_updated = 0
    
    # ë°°ì¹˜ë³„ë¡œ ì²˜ë¦¬
    for batch_num in range(0, total_urls, batch_size):
        batch_end = min(batch_num + batch_size, total_urls)
        batch_urls = missing_urls[batch_num:batch_end]
        
        print(f"\n=== ë°°ì¹˜ {batch_num//batch_size + 1}: {batch_num + 1}~{batch_end}ë²ˆì§¸ URL ì²˜ë¦¬ ===")
        
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            context = browser.new_context()
            stealth_sync(context)
            page = context.new_page()
            
            batch_updated = 0
            
            for i, (row_idx, url) in enumerate(batch_urls, 1):
                current_num = batch_num + i
                print(f"[{current_num}/{total_urls}] ì²˜ë¦¬ ì¤‘: í–‰ {row_idx} - {url[:50]}...")
                
                try:
                    end_date = extract_end_date_only(page, url)
                    
                    if end_date and end_date not in ["ì¢…ë£Œì¼ ì°¾ì„ ìˆ˜ ì—†ìŒ", "í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨", "ì¢…ë£Œì¼ ì •ë³´ ì—†ìŒ"]:
                        # DataFrame ì—…ë°ì´íŠ¸ (0-based index)
                        df.at[row_idx - 1, end_date_col] = end_date
                        batch_updated += 1
                        total_updated += 1
                        print(f"  âœ… ì—…ë°ì´íŠ¸: {end_date}")
                    else:
                        print(f"  âŒ ì‹¤íŒ¨: {end_date}")
                    
                    # ìš”ì²­ ê°„ ë”œë ˆì´
                    time.sleep(1)
                    
                except Exception as e:
                    print(f"  âŒ ì˜¤ë¥˜: {str(e)[:50]}")
                    continue
            
            browser.close()
            
            print(f"ë°°ì¹˜ {batch_num//batch_size + 1} ì™„ë£Œ: {batch_updated}ê°œ ì—…ë°ì´íŠ¸")
            
            # ì¤‘ê°„ ì €ì¥ (ë°°ì¹˜ë§ˆë‹¤)
            if batch_updated > 0:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                temp_filename = f"ìµœì¢…í•©ë³¸_ì¢…ë£Œì¼ë°°ì¹˜_{batch_num//batch_size + 1}_{timestamp}.xlsx"
                df.to_excel(temp_filename, index=False)
                print(f"ì¤‘ê°„ ì €ì¥: {temp_filename}")
    
    # ìµœì¢… ì €ì¥
    if total_updated > 0:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        final_filename = f"ìµœì¢…í•©ë³¸_ì¢…ë£Œì¼ì „ì²´ì™„ë£Œ_{timestamp}.xlsx"
        df.to_excel(final_filename, index=False)
        print(f"\nğŸ‰ ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ! {total_updated}ê°œ í–‰ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ìµœì¢… íŒŒì¼: {final_filename}")
    else:
        print("ì—…ë°ì´íŠ¸ëœ í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    print("ì¢…ë£Œì¼ ëˆ„ë½ ë¬¸ì œ í•´ê²° ë„êµ¬")
    print("1: ëˆ„ë½ëœ ì¢…ë£Œì¼ í™•ì¸ë§Œ")
    print("2: ì¢…ë£Œì¼ ë‹¤ì‹œ ìŠ¤í¬ë˜í•‘ (ìµœëŒ€ 50ê°œ)")
    print("3: ì¢…ë£Œì¼ ë‹¤ì‹œ ìŠ¤í¬ë˜í•‘ (ìµœëŒ€ 10ê°œ - í…ŒìŠ¤íŠ¸ìš©)")
    print("4: ëª¨ë“  ëˆ„ë½ëœ ì¢…ë£Œì¼ ì²˜ë¦¬ (898ê°œ ì „ì²´)")
    print("5: ì‚¬ìš©ì ì§€ì • ê°œìˆ˜ë¡œ ì²˜ë¦¬")
    print("6: ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì•ˆì „í•˜ê²Œ ì „ì²´ ì²˜ë¦¬ (100ê°œì”©)")
    
    choice = input("ì„ íƒ (1, 2, 3, 4, 5, 6): ")
    
    if choice == "1":
        missing_urls = find_missing_end_dates()
        if missing_urls:
            print("\\nëˆ„ë½ëœ ì¢…ë£Œì¼ì´ ìˆëŠ” í–‰ë“¤:")
            for row_idx, url in missing_urls[:10]:  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
                print(f"í–‰ {row_idx}: {url[:60]}...")
            if len(missing_urls) > 10:
                print(f"... ì™¸ {len(missing_urls) - 10}ê°œ ë”")
    
    elif choice == "2":
        fix_missing_end_dates(max_urls=50)
    
    elif choice == "3":
        fix_missing_end_dates(max_urls=10)
    
    elif choice == "4":
        print("âš ï¸ 898ê°œ URLì„ ëª¨ë‘ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        confirm = input("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if confirm.lower() == 'y':
            fix_missing_end_dates(max_urls=898)
        else:
            print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    elif choice == "5":
        try:
            max_count = int(input("ì²˜ë¦¬í•  URL ê°œìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))
            fix_missing_end_dates(max_urls=max_count)
        except ValueError:
            print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    elif choice == "6":
        print("âš ï¸ 898ê°œ URLì„ ë°°ì¹˜ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        print("100ê°œì”© ì²˜ë¦¬í•˜ë©°, ê° ë°°ì¹˜ë§ˆë‹¤ ì¤‘ê°„ ì €ì¥ë©ë‹ˆë‹¤.")
        confirm = input("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if confirm.lower() == 'y':
            fix_missing_end_dates_batch()
        else:
            print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
